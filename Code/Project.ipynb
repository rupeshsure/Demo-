#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd   
import numpy as np    
import matplotlib.pyplot as plt 
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_formats = ['retina']")
import seaborn as sns
import time
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn import metrics
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss
from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve
from sklearn.metrics import fbeta_score, cohen_kappa_score
SEED = 42


# In[2]:


df = pd.read_csv('modify.csv')
df.head()


# In[3]:


print ('Rows     : ', df.shape[0])
print ('Columns  : ', df.shape[1])
print ('\nFeatures : \n', df.columns.tolist())
print ('\nMissing values :  ', df.isnull().sum().values.sum())
print ('\nUnique values :  \n', df.nunique())


# In[4]:


df.info()
df.isnull().sum()


# In[5]:


# value_counts command is to give no.of 0's and 1's in outcome column
#legend command is to give thae which outcomes is belongs to which color
df = pd.read_csv('modify.csv')
print(df.Outcome.value_counts())
color=['r',"pink"]
df['Outcome'].value_counts().plot.pie(colors=color).set_title('Diabetes Outcome')
plt.legend()
plt.show()


# In[6]:


df.Outcome.value_counts()[1] / df.Outcome.count()


# In[7]:


df.Outcome.value_counts()[0] / df.Outcome.count()


# In[8]:


df.describe()


# In[9]:


sns.pairplot(df, hue='Outcome', plot_kws=dict(alpha=.3, edgecolor='none'), height=2, aspect=1.1)


# In[10]:



sns.set(style="white")
# Generate a mask for the upper triangle
mask = np.zeros_like(df.corr(), dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
# Set up the matplotlib figure to control size of heatmap
fig, ax = plt.subplots(figsize=(8,8))
# Create a custom color palette
cmap = sns.diverging_palette(255, 10, as_cmap=True)  # as_cmap returns a matplotlib colormap object rather than a list of colors
# Red=10, Green=128, Blue=255
# Plot the heatmap
sns.heatmap(df.corr(), mask=mask, annot=True, square=True, cmap=cmap , vmin=-1, vmax=1, ax=ax)  # annot display corr label
# Prevent Heatmap Cut-Off Issue
bottom, top = ax.get_ylim()
ax.set_ylim(bottom+0.5, top-0.5)


# In[11]:


# To analyse feature-outcome distribution in visualisation
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

ROWS, COLS = 2, 4
fig, ax = plt.subplots(ROWS, COLS, figsize=(18,8) )
row, col = 0, 0
for i, feature in enumerate(features):
    if col == COLS - 1:
        row += 1
    col = i % COLS
    
#     df[feature].hist(bins=35, color='green', alpha=0.5, ax=ax[row, col]).set_title(feature)  #show all, comment off below 2 lines
    df[df.Outcome==0][feature].hist(bins=35, color='blue', alpha=0.5, ax=ax[row, col]).set_title(feature)
    df[df.Outcome==1][feature].hist(bins=35, color='orange', alpha=0.7, ax=ax[row, col])
    
plt.legend(['No Diabetes', 'Diabetes'])
fig.subplots_adjust(hspace=0.3)


# In[12]:



X, y = df.drop('Outcome', axis=1), df['Outcome']
print(X.shape, y.shape)


# In[13]:


rfc = RandomForestClassifier(random_state=SEED, n_estimators=100)

# Train model, note that NO scaling is required
rfc_model = rfc.fit(X, y)

# Plot the top features based on its importance
(pd.Series(rfc_model.feature_importances_, index=X.columns)
    .nlargest(10)   # can adjust based on how many top features you want
    .plot(kind='barh', figsize=[8,4])
    .invert_yaxis()) # Ensures that the feature with the most importance is on top, in descending order

plt.yticks(size=15)
plt.title('Top Features derived by Random Forest', size=20)


# In[14]:


X = df.drop('Outcome', axis=1)   # axis=0 for row, axis=1 for column
y = df['Outcome']

# split data to 80:20 ratio for train/test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)
print('X_train', X_train.shape)
print('y_train', y_train.shape)
print('X_test', X_test.shape)
print('y_test', y_test.shape)


# In[15]:


def evaluate(model, X_test , y_test,modelname):
  y_pred1=model.predict(X_test)
  precision    = precision_score(y_test, y_pred1)
  recall       = recall_score(y_test, y_pred1)
  f1score      = f1_score(y_test, y_pred1) 
  rocauc       = roc_auc_score(y_test, y_pred1)
  logloss      = log_loss(y_test, y_pred1)
  accuracy     = accuracy_score(y_test, y_pred1)
  confusion    = confusion_matrix(y_test, y_pred1)
  df_model1 = pd.DataFrame({  'model'        : [modelname],
                             'accuracy'     : [accuracy],
                             'precision'    : [precision],
                             'recall'       : [recall],
                             'f1score'      : [f1score],
                             'rocauc'       : [rocauc],
                             'logloss'      : [logloss],
                             'timetaken'    : [time2],
                            'confusionmatrix' : [confusion]
                            
                                }) 
  return df_model1


# ### BASE LINE MODEL EVALUATION

# In[16]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model = RandomForestClassifier()\nbase_model.fit(X_train, y_train)\n#base_accuracy = evaluate(base_model, X_test, y_test,modelname)\nmodel1 = evaluate(base_model,  X_test,  y_test, \'RandomForest\')\nmodel1.timetaken[0] = time.time() - time2\nprint("Random Forest")\nprint(base_model.get_params())\n')


# In[17]:


get_ipython().run_cell_magic('time', '', 'from sklearn.ensemble import ExtraTreesClassifier\n\ntime2=time.time()\nprint("base model")\nbase_model1 = ExtraTreesClassifier()\nbase_model1.fit(X_train, y_train)\nmodel2 = evaluate(base_model1,  X_test,  y_test, \'Extra Tree\')\nmodel2.timetaken[0] = time.time() - time2\nprint("Extra Tree")\nprint(base_model1.get_params())')


# In[18]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model2 = LogisticRegression()\nbase_model2.fit(X_train, y_train)\nmodel3 = evaluate(base_model2,  X_test,  y_test, \'Logistic Regression\')\nmodel3.timetaken[0] = time.time() - time2\nprint("Logoistic Regression")\nprint(base_model2.get_params())')


# In[19]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model3 = KNeighborsClassifier()\nbase_model3.fit(X_train, y_train)\nmodel4 = evaluate(base_model3,  X_test,  y_test, \'KNN\')\nmodel4.timetaken[0] = time.time() - time2\nprint("KNN")\nprint(base_model3.get_params())')


# In[20]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model4 = LinearSVC()\nbase_model4.fit(X_train, y_train)\nmodel5 = evaluate(base_model4,  X_test,  y_test, \'LinearSVC\')\nmodel5.timetaken[0] = time.time() - time2\nprint("LinearSVC")\nprint(base_model4.get_params())')


# In[21]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model5 = GaussianNB()\nbase_model5.fit(X_train, y_train)\nmodel6 = evaluate(base_model5,  X_test,  y_test, \'GaussianNB\')\nmodel6.timetaken[0] = time.time() - time2\nprint("GaussianNB")\nprint(base_model5.get_params())')


# In[22]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model6=SVC()\nbase_model6.fit(X_train, y_train)\nmodel7 = evaluate(base_model6,  X_test,  y_test, \'SVC\')\nmodel7.timetaken[0] = time.time() - time2\nprint("SVC")\nprint(base_model6.get_params())')


# In[23]:


get_ipython().run_cell_magic('time', '', 'time2=time.time()\nprint("base model")\nbase_model7=DecisionTreeClassifier()\nbase_model7.fit(X_train, y_train)\nmodel8 = evaluate(base_model7,  X_test,  y_test, \'Decision Tree\')\nmodel8.timetaken[0] = time.time() - time2\nprint("Decision Tree")\nprint(base_model7.get_params())')


# #### PERFORMANCE METRICS OF BASE MODEL

# In[24]:


df_base= pd.concat([model1,model2,model3,model4,model5,model6,model7,model8],axis = 0).reset_index()
df_base.drop('index', axis=1, inplace=True)
df_base


# ### HYPERPARAMETER TUNING TECHNIQUE

# #### RANDOMIZED SEARCH CV

# In[25]:


from sklearn.model_selection import RandomizedSearchCV


# In[26]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nrandom_grid={\'bootstrap\': [True],\n \'max_depth\': [None],\n \'max_features\': [\'auto\'],\n \'min_samples_leaf\': [1], #intial 1\n \'min_samples_split\': [5],\n \'n_estimators\': [800]}\n\nrf = RandomForestClassifier(random_state=42)\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)\nbest_random = rf_random.best_estimator_\nmodel11=evaluate(best_random,  X_test,  y_test, \'RandomForest\')\nmodel11.timetaken[0] = time.time() - time1\nprint("randomized model of Random Forest")')


# In[27]:


print("Classification report of Random Forest")
print('\n')
clf = RandomForestClassifier(**rf_random.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[28]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_et={\'bootstrap\': [False],\n \'max_depth\': [70],\n \'max_features\': [\'sqrt\'],\n \'min_samples_leaf\': [2],\n \'min_samples_split\': [5],\n \'n_estimators\': [1600]\n }\netc = ExtraTreesClassifier(random_state=42)\nETC = RandomizedSearchCV(estimator = etc, param_distributions = param_grid_et, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nETC.fit(X_train, y_train)\nbest_ETC = ETC.best_estimator_\nmodel12=evaluate(best_ETC,  X_test,  y_test, \'Extra Tree\')\nmodel12.timetaken[0] = time.time() - time1\nprint("randomized model of Extra Tree")\n\n')


# In[29]:


print("Classification report of Extra Tree")
print('\n')
clf = ExtraTreesClassifier(**ETC.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[30]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_lr={\'C\': [6.0],\n \'max_iter\': [490],\n \'solver\': [\'newton-cg\'],\n }\nLr = LogisticRegression(random_state=42)\nLR = RandomizedSearchCV(estimator = Lr, param_distributions = param_grid_lr, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nLR.fit(X_train, y_train)\nbest_LR = LR.best_estimator_\nmodel13=evaluate(best_LR,  X_test,  y_test, \'Logistic Regression\')\nmodel13.timetaken[0] = time.time() - time1\nprint("randomized model of Logistic Regression")\n\n')


# In[31]:


print("Classification report of Logistic Regression")
print('\n')
clf = LogisticRegression(**LR.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[32]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_kn={\'algorithm\': [\'auto\'], \'leaf_size\': [200], \'p\': [3]} #intial p is 2\nknn = KNeighborsClassifier(n_neighbors=42)\nKNN = RandomizedSearchCV(estimator = knn, param_distributions = param_grid_kn, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nKNN.fit(X_train, y_train)\n\nbest_KNN = KNN.best_estimator_\nmodel14=evaluate(best_KNN,  X_test,  y_test, \'KNN\')\nmodel14.timetaken[0] = time.time() - time1\nprint("randomized model of KNN")\n')


# In[33]:


print("Classification report of KNN")
print('\n')
clf = KNeighborsClassifier(**KNN.best_params_, n_neighbors=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[34]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_lsvc={\n    \'class_weight\': [None], \'dual\': [False], \'intercept_scaling\': [8], \'tol\': [1e-05], \'max_iter\' : [200]\n}\nlsvc =LinearSVC(random_state=42)\nLSVC = RandomizedSearchCV(estimator = lsvc, param_distributions = param_grid_lsvc, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nLSVC.fit(X_train, y_train)\n\nbest_LSVC= LSVC.best_estimator_\nmodel15=evaluate(best_LSVC,  X_test,  y_test, \'LinearSVC\')\nmodel15.timetaken[0] = time.time() - time1\nprint("randomized model of LinearSVC")\n\n')


# In[35]:


print("Classification report of LinearSVC")
print('\n')
clf = LinearSVC(**LSVC.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[36]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_gnb={ \'priors\': [None], \'var_smoothing\': [1e-20]   #intaial -09\n}\ngnb =GaussianNB()\nGNB = RandomizedSearchCV(estimator = gnb, param_distributions = param_grid_gnb, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nGNB.fit(X_train, y_train)\n\nbest_GNB= GNB.best_estimator_\nmodel16=evaluate(best_GNB,  X_test,  y_test, \'GassuianNB\')\nmodel16.timetaken[0] = time.time() - time1\nprint("randomized model of GaussianNB")\n')


# In[37]:


print("Classification report of GaussianNB")
print('\n')
clf = GaussianNB(**GNB.best_params_)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[38]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\nparam_grid_svc={\'break_ties\': [True],\n               \'cache_size\': [211], \n               \'degree\' : [8],\n               \'class_weight\': [None],\n               \'tol\': [0.01] \n               }\nsvc=SVC(random_state=42)\nSVc = RandomizedSearchCV(estimator = svc, param_distributions = param_grid_svc, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nSVc.fit(X_train, y_train)\n\nbest_SVc= SVc.best_estimator_\nmodel17=evaluate(best_SVc,  X_test,  y_test, \'SVC\')\nmodel17.timetaken[0] = time.time() - time1\nprint("randomized model of SVC")\n')


# In[39]:


print("Classification report of SVC")
print('\n')
clf = SVC(**SVc.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[40]:


get_ipython().run_cell_magic('time', '', 'time1 = time.time()\ndt = DecisionTreeClassifier(random_state=42)\nparam_grid_dt={\n \'class_weight\': [None],\n \'max_depth\': [60],\n \'max_features\': [\'sqrt\'],\n \'min_samples_leaf\': [2],\n \'min_samples_split\': [10]\n}\nDTC = RandomizedSearchCV(estimator = dt, param_distributions = param_grid_dt, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nDTC.fit(X_train, y_train)\n\nbest_DTC= DTC.best_estimator_\nmodel18=evaluate(best_DTC,  X_test,  y_test, \'Decision Tree\')\nmodel18.timetaken[0] = time.time() - time1\nprint("randomized model of Decision Tree")\n\n\n')


# In[41]:


print("Classification report of Decision Tree")
print('\n')
clf = DecisionTreeClassifier(**DTC.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# #### PERFORMANCE METRICS OF RANDOMIZED MODEL

# In[42]:


df_randomized= pd.concat([model11,model12,model13,model14,model15,model16,model17,model18],axis = 0).reset_index()
df_randomized.drop('index', axis=1, inplace=True)
df_randomized


# ### NATURE INSPIRIED ALGORITHM

# In[43]:


get_ipython().system(' pip install sklearn_nature_inspired_algorithms==0.4.3')
get_ipython().system(' pip install NiaPy')
get_ipython().system(' pip install algorithms')
from sklearn_nature_inspired_algorithms.model_selection.nature_inspired_search_cv import NatureInspiredSearchCV
from sklearn_nature_inspired_algorithms.helpers import score_by_generation_lineplot
from sklearn.metrics import classification_report


# 
# #### BAT ALGORITHM

# In[44]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\ntime1 = time.time()\n\nparam_grid={\'bootstrap\': [True],\n \'max_depth\': [70],\n \'max_features\': [\'auto\'],\n \'min_samples_leaf\':[2], #Intial condition is 1 but changed to 2\n \'min_samples_split\': [5],\n \'n_estimators\': [800]\n }\n\nclf_1 = RandomForestClassifier(random_state=42)\nnia_search = NatureInspiredSearchCV(\n    clf_1,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42)\n    \n    # or any number if you want same results on each run\n\n\nnia_search.fit(X_train, y_train)\nprint("Bat model")\n\nprint("Random Forest")\n\nba_random= nia_search.best_estimator_\nmodel21=evaluate(ba_random, X_test, y_test,\'Random Forest\')\nmodel21.timetaken[0] = time.time() - time1\n\n')


# In[45]:


score_by_generation_lineplot(nia_search)


# In[46]:


print("Classification report of Random Forest")
print('\n')
clf = RandomForestClassifier(**nia_search.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[47]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\'bootstrap\': [True],\n \'max_depth\': [110],\n \'max_features\': [\'auto\'],\n \'min_samples_leaf\':[2], #intaial 1\n \'min_samples_split\': [5],\n \'n_estimators\': [800]}\nclf_2 = ExtraTreesClassifier(random_state=42)\n\nnia_search2 = NatureInspiredSearchCV(\n    clf_2,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42\n)\n    # or any number if you want same results on each run\n\n\nnia_search2.fit(X_train, y_train)\nprint("Bat model")\n\nprint("Extra Tree")\n\nba_et= nia_search2.best_estimator_\nmodel22=evaluate(ba_et,  X_test,  y_test, \'Extra Tree\')\nmodel22.timetaken[0] = time.time() - time1')


# In[48]:


score_by_generation_lineplot(nia_search2)


# In[49]:


print("Classification report of Extra Tree")
print('\n')
clf = ExtraTreesClassifier(**nia_search2.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[50]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid_lr={\'max_iter\': [1200], \'solver\': [\'newton-cg\'], \'C\': [4.0]}\nclf_1 = LogisticRegression(random_state=42)\n\nnia_search1 = NatureInspiredSearchCV(\n    clf_1,\n    param_grid_lr,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search1.fit(X_train, y_train)\nprint("Bat model")\n\nprint("Logistic Regression")\n\nba_lr= nia_search1.best_estimator_\nmodel23=evaluate(ba_lr,  X_test,  y_test, \'Logistic Regression\')\nmodel23.timetaken[0] = time.time() - time1\n\n')


# In[51]:


score_by_generation_lineplot(nia_search1)


# In[52]:


print("Classification report of Logistic Regression")
print('\n')
clf = LogisticRegression(**nia_search1.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[53]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nclf_4 = KNeighborsClassifier(n_neighbors=42)\nparam_grid={\'algorithm\': [\'kd_tree\'], \'leaf_size\': [133], \'p\': [2]} \nnia_search4 = NatureInspiredSearchCV(\n    clf_4,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search4.fit(X_train, y_train)\nprint("Bat model")\n\nprint("KNN")\n\nba_kn= nia_search4.best_estimator_\nmodel24=evaluate(ba_kn , X_test,  y_test, \'KNN\')\nmodel24.timetaken[0] = time.time() - time1\n\n')


# In[54]:


score_by_generation_lineplot(nia_search4)


# In[55]:


print("Classification report of KNN")
print('\n')
clf =KNeighborsClassifier(**nia_search4.best_params_, n_neighbors=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[56]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid_lsvc={\'dual\': [False], \'intercept_scaling\': [50], \'tol\': [1e-05], \'max_iter\': [1700]\n                 }\nclf_5 = LinearSVC(random_state=42)\n\nnia_search5 = NatureInspiredSearchCV(\n    clf_5,\n    param_grid_lsvc,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search5.fit(X_train, y_train)\nprint("Bat model")\n\nprint("LinearSVC")\n\nba_lsvc= nia_search5.best_estimator_\nmodel25=evaluate(ba_lsvc , X_test,  y_test, \'LinearSVC\')\nmodel25.timetaken[0] = time.time() - time1\n\n')


# In[57]:


score_by_generation_lineplot(nia_search5)


# In[58]:


print("Classification report of LinearSVC")
print('\n')
clf =LinearSVC(**nia_search5.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[59]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid_gnb={\'priors\' :[None], \'var_smoothing\' : [1e-20]}\nclf_6 = GaussianNB()\n\nnia_search6 = NatureInspiredSearchCV(\n    clf_6,\n    param_grid_gnb,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search6.fit(X_train, y_train)\nprint("Bat model")\n\nprint("GaussianNB")\n\nba_gnb= nia_search6.best_estimator_\nmodel26=evaluate(ba_gnb , X_test,  y_test, \'GaussianNB\')\nmodel26.timetaken[0] = time.time() - time1\n')


# In[60]:


score_by_generation_lineplot(nia_search6)


# In[61]:


print("Classification report of GaussianNB")
print('\n')
clf =GaussianNB(**nia_search6.best_params_)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[62]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid_svc={\'break_ties\': [False], \'cache_size\': [200], \'tol\': [1e-05], \'degree\': [4]}\nclf_8 = SVC(random_state=42)\n\nnia_search8 = NatureInspiredSearchCV(\n    clf_8,\n    param_grid_svc,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search8.fit(X_train, y_train)\nprint("Bat model")\n\nprint("SVC")\n\nba_svc= nia_search8.best_estimator_\nmodel27=evaluate(ba_svc , X_test,  y_test, \'SVC\')\nmodel27.timetaken[0] = time.time() - time1\n')


# In[63]:


score_by_generation_lineplot(nia_search8)


# In[64]:


print("Classification report of SVC")
print('\n')
clf = SVC(**nia_search8.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[65]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\n \'max_depth\': [115],\n \'max_features\': [\'sqrt\'],\n \'min_samples_leaf\':[4],\n \'min_samples_split\': [5],\n }\nclf_3 = DecisionTreeClassifier(random_state=42)\n\nnia_search3 = NatureInspiredSearchCV(\n    clf_3,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\nprint("Bat Model")\nprint("Decision Tree")\nnia_search3.fit(X_train, y_train)\n\n\nba_dt= nia_search3.best_estimator_\nmodel28=evaluate(ba_dt,  X_test,  y_test, \'Decision Tree\')\nmodel28.timetaken[0] = time.time() - time1\n\n')


# In[66]:


score_by_generation_lineplot(nia_search3)


# In[67]:


print("Classification report of Decision Tree")
print('\n')
clf = DecisionTreeClassifier(**nia_search3.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# #### PERFORMANCE METRICS OF BAT ALGORITHM

# In[68]:


df_bat= pd.concat([model21,model22,model23,model24,model25,model26,model27,model28],axis = 0).reset_index()
df_bat.drop('index', axis=1, inplace=True)
df_bat


# #### HYBRID BAT ALGORITHM
# 

# In[69]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\ntime1 = time.time()\nparam_grid={\'bootstrap\': [True],  \n            \'max_depth\' : [None], \n            \'max_features\' : [\'auto\'],\n            \'min_samples_leaf\' : [2], #intial 1\n            \'min_samples_split\' : [5],\n            \'n_estimators\' : [200]\n                      }\nrfc = RandomForestClassifier(random_state=42)\nnia_search = NatureInspiredSearchCV(\n    rfc,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybrid bat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("Random Forest")\n\nhba_random= nia_search.best_estimator_\nmodel31=evaluate(hba_random,  X_test,  y_test, \'Random Forest\')\nmodel31.timetaken[0] = time.time() - time1\n')


# In[70]:


score_by_generation_lineplot(nia_search)


# In[71]:


print("Classification report of Random Forest")
print('\n')
clf = RandomForestClassifier(**nia_search.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[72]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nclf_12 = ExtraTreesClassifier(random_state=42)\nparam_grid={\n    \'bootstrap\' :[True], \'max_depth\' : [110], \'max_features\' : [\'auto\'],\n    \'min_samples_leaf\' : [2], \'min_samples_split\' : [5],\n    \'n_estimators\' : [200] #intial 1\n}\nnia_search12 = NatureInspiredSearchCV(\n    clf_12,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search12.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("Extra Tree")\n\nhba_et= nia_search12.best_estimator_\nmodel32=evaluate(hba_et,  X_test,  y_test, \'Extra Tree\')\nmodel32.timetaken[0] = time.time() - time1\n\n')


# In[73]:


score_by_generation_lineplot(nia_search12)


# In[74]:


print("Classification report of Extra Tree")
print('\n')
clf =ExtraTreesClassifier(**nia_search12.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[75]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid_lr={\'max_iter\': [882], \'solver\': [\'newton-cg\'], \'C\':[10.0]}\nclf_13 = LogisticRegression(random_state=42)\n\nnia_search13 = NatureInspiredSearchCV(\n    clf_13,\n    param_grid_lr,\n    cv=3,\n    verbose=2,\n    algorithm=\'ba\', #  bat algorithm\n    population_size=150,\n    max_n_gen=200,\n    max_stagnating_gen=60,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search13.fit(X_train, y_train)\nprint("Bat model")\n\nprint("Logistic Regression")\n\nhba_lr= nia_search13.best_estimator_\nmodel33=evaluate(hba_lr,  X_test,  y_test, \'Logistic Regression\')\nmodel33.timetaken[0] = time.time() - time1\n')


# In[76]:


score_by_generation_lineplot(nia_search13)


# In[77]:


print("Classification report of Logistic Regression")
print('\n')
clf = LogisticRegression(**nia_search13.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[78]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={ \n    \'algorithm\' :[\'kd_tree\'], \'leaf_size\' : [133],\'p\' :[2]\n}\nclf_14 = KNeighborsClassifier(n_neighbors=42)\n\nnia_search14 = NatureInspiredSearchCV(\n    clf_14,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search14.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("KNN")\n\nhba_kn= nia_search14.best_estimator_\nmodel34=evaluate(hba_kn , X_test,  y_test, \'KNN\')\nmodel34.timetaken[0] = time.time() - time1')


# In[79]:


score_by_generation_lineplot(nia_search14)


# In[80]:


print("Classification report of KNN")
print('\n')
clf = KNeighborsClassifier(**nia_search14.best_params_, n_neighbors=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[81]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\n    \'intercept_scaling\':[50],\n    \'max_iter\' :[1700],\n    \'dual\' : [False],\n    \'tol\' : [1e-05]\n\n}\nclf_15 = LinearSVC(random_state=42)\n\nnia_search15 = NatureInspiredSearchCV(\n    clf_15,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search15.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("LinearSVC")\n\nhba_lsvc= nia_search15.best_estimator_\nmodel35=evaluate(hba_lsvc , X_test,  y_test, \'LinearSVC\')\nmodel35.timetaken[0] = time.time() - time1\n')


# In[82]:


score_by_generation_lineplot(nia_search15)


# In[83]:


print("Classification report of LinearSVC")
print('\n')

clf = LinearSVC(**nia_search15.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[84]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\n   \'priors\' : [None], \'var_smoothing\' : [1e-20] \n}\nclf_16 = GaussianNB()\n\nnia_search16 = NatureInspiredSearchCV(\n    clf_16,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search16.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("GaussianNB")\n\nhba_gnb= nia_search16.best_estimator_\nmodel36=evaluate(hba_gnb , X_test,  y_test, \'GaussianNB\')\nmodel36.timetaken[0] = time.time() - time1\n\n')


# In[85]:


score_by_generation_lineplot(nia_search16)


# In[86]:


print("Classification report of GaussianNB")
print('\n')

clf = GaussianNB(**nia_search16.best_params_)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[87]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\n    \'tol\': [0.001],\n    \'cache_size\': [1600],\n    \'break_ties\': [False],\n    \'degree\': [8]\n    \n}\nclf_18 = SVC(random_state=42)\n\nnia_search18 = NatureInspiredSearchCV(\n    clf_18,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search18.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("SVC")\n\nhba_svc= nia_search18.best_estimator_\nmodel37=evaluate(hba_svc , X_test,  y_test, \'SVC\')\nmodel37.timetaken[0] = time.time() - time1\n')


# In[88]:


score_by_generation_lineplot(nia_search18)


# In[89]:


print("Classification report of SVC")
print('\n')

clf = SVC(**nia_search18.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[90]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nparam_grid={\n    \'max_features\': [\'sqrt\'],\n    \'max_depth\': [187],\n    \'min_samples_split\': [15],\n    \'min_samples_leaf\': [2]\n    \n}\nclf_40 = DecisionTreeClassifier(random_state=42)\n\nnia_search40 = NatureInspiredSearchCV(\n    clf_40,\n    param_grid,\n    cv=3,\n    verbose=2,\n    algorithm=\'hba\', #  Hybridbat algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search40.fit(X_train, y_train)\nprint("Hybrid Bat model")\n\nprint("Decision Tree")\n\nhba_dt= nia_search40.best_estimator_\nmodel38=evaluate(hba_dt,  X_test,  y_test, \'Decision Tree\')\nmodel38.timetaken[0] = time.time() - time1\n\n')


# In[91]:


score_by_generation_lineplot(nia_search40)


# In[92]:


print("Classification report of Decision Tree")
print('\n')
clf = DecisionTreeClassifier(**nia_search40.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# #### PERFORMANCE METRICS OF HYBRID BAT MODEL

# In[93]:


df_hba= pd.concat([model31,model32,model33,model34,model35,model36,model37,model38],axis = 0).reset_index()
df_hba.drop('index', axis=1, inplace=True)
df_hba


# #### GREY WOLF OPTIMIZER

# In[94]:


get_ipython().run_cell_magic('time', '', '\nfrom sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\ntime1 = time.time()\nparam_grid_rt={\'n_estimators\': [400,100],\n \'max_features\': [\'sqrt\'],\n \'max_depth\': [40,None],\n \'min_samples_split\': [2,5], #intial 2\n \'min_samples_leaf\': [2,5],\n \'bootstrap\': [True]}\n\nclf_21 = RandomForestClassifier(random_state=42)\nnia_search21 = NatureInspiredSearchCV(\n    clf_21,\n    param_grid_rt,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search21.fit(X_train, y_train)\nprint("Greywolf model")\n\nprint("Random Forest")\n\ngwa_random= nia_search21.best_estimator_\nmodel41=evaluate(gwa_random,  X_test,  y_test, \'Random Forest\')\nmodel41.timetaken[0] = time.time() - time1\n')


# In[95]:


nia_search21.best_params_


# In[96]:


score_by_generation_lineplot(nia_search21)


# In[97]:


print("Classification report of Random Forest")
print('\n')
clf = RandomForestClassifier(**nia_search21.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[98]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.ensemble import ExtraTreesClassifier\nparam_grid_et={\'n_estimators\': [1000,100],\n \'max_features\': [\'sqrt\'],\n \'max_depth\': [10,None],\n \'min_samples_split\': [5,2], #intial is 2\n \'min_samples_leaf\': [2,1], #intial 1\n \'bootstrap\': [True]}\n\nclf_22 = ExtraTreesClassifier(random_state=42)\n\nnia_search22 = NatureInspiredSearchCV(\n    clf_22,\n    param_grid_et,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search22.fit(X_train, y_train)\nprint("Greywolf model")\n\nprint("Extra Tree")\n\ngwa_et= nia_search22.best_estimator_\nmodel42=evaluate(gwa_et,  X_test,  y_test, \'Extra Tree\')\nmodel42.timetaken[0] = time.time() - time1\n')


# In[99]:


nia_search22.best_params_


# In[100]:


score_by_generation_lineplot(nia_search22)


# In[101]:


print("Classification report of Extra Tree")
print('\n')
clf = ExtraTreesClassifier(**nia_search22.best_params_,random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[102]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.linear_model import LogisticRegression\nparam_grid_lr={\'max_iter\': [1200,100], \'solver\': [\'newton-cg\',\'sag\'] ,\'C\': [4.0,1.0]\n              }\n\nclf_23 = LogisticRegression(random_state=42)\n\nnia_search23 = NatureInspiredSearchCV(\n    clf_23,\n    param_grid_lr,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search23.fit(X_train, y_train)\nprint("Greywolf model")\n\nprint("Logistic Regression")\n\ngwa_lr= nia_search23.best_estimator_\nmodel43=evaluate(gwa_lr,  X_test,  y_test, \'Logistic Regression\')\nmodel43.timetaken[0] = time.time() - time1\n')


# In[103]:


nia_search23.best_params_


# In[104]:


score_by_generation_lineplot(nia_search23)


# In[105]:


print("Classification report of Logistic Regression")
print('\n')
clf = LogisticRegression(**nia_search23.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[106]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.neighbors import KNeighborsClassifier\nparam_grid_kn={\'algorithm\': [\'kd_tree\',\'auto\'],\'leaf_size\': [133,40,30], \'p\': [2,1,3]}\n\nclf_24 = KNeighborsClassifier(n_neighbors=42)\n\nnia_search24 = NatureInspiredSearchCV(\n    clf_24,\n    param_grid_kn,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search24.fit(X_train, y_train)\nprint("Greywolf  model")\n\nprint("KNN")\n\ngwa_kn= nia_search24.best_estimator_\nmodel44=evaluate(gwa_kn , X_test,  y_test, \'KNN\')\nmodel44.timetaken[0] = time.time() - time1')


# In[107]:


nia_search24.best_params_


# In[108]:


score_by_generation_lineplot(nia_search24)


# In[109]:


print("Classification report of KNN")
print('\n')
clf = KNeighborsClassifier(**nia_search24.best_params_, n_neighbors=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[110]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.svm import LinearSVC\nparam_grid_lsvc={\'tol\': [1e-05,0.0001], \'intercept_scaling\': [50,1], \'dual\': [False], \'max_iter\': [1700,100]}\n\nclf_25 = LinearSVC(random_state=42)\n\nnia_search25 = NatureInspiredSearchCV(\n    clf_25,\n    param_grid_lsvc,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search25.fit(X_train, y_train)\nprint("Greywolf  model")\n\nprint("LinearSVC")\n\ngwa_lsvc= nia_search25.best_estimator_\nmodel45=evaluate(gwa_lsvc , X_test,  y_test, \'LinearSVC\')\nmodel45.timetaken[0] = time.time() - time1')


# In[111]:


nia_search25.best_params_


# In[112]:


score_by_generation_lineplot(nia_search25)


# In[113]:


print("Classification report of LinearSVC")
print('\n')
clf = LinearSVC(**nia_search25.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[114]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nvar_smoothing=[0.0000000001,0.000001,0.01,0.001,0.00000000000001,1,1e-15,1e-20]\nparam_grid_gnb = {             \n               \'var_smoothing\' : var_smoothing\n               }\nprint(param_grid_gnb)\nclf_26 = GaussianNB()\n\nnia_search26 = NatureInspiredSearchCV(\n    clf_26,\n    param_grid_gnb,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search26.fit(X_train, y_train)\nprint("Greywolf  model")\n\nprint("GaussianNB")\n\ngwa_gnb= nia_search26.best_estimator_\nmodel46=evaluate(gwa_gnb , X_test,  y_test, \'GaussianNB\')\nmodel46.timetaken[0] = time.time() - time1\n')


# In[115]:


nia_search6.best_params_


# In[116]:


score_by_generation_lineplot(nia_search26)


# In[117]:


print("Classification report of GaussianNB")
print('\n')
clf = GaussianNB(**nia_search26.best_params_)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[118]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.svm import SVC\nparam_grid_svc = {\'C\' : [6,10],\n               \'degree\': [5,9],              \n               \'tol\': [0.01,0.1],\n               \'cache_size\': [200,1000],\n               \'break_ties\': [False]\n               }\nprint(param_grid_svc)\nclf_27= SVC()\n\nnia_search27 = NatureInspiredSearchCV(\n    clf_27,\n    param_grid_svc,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #  Greywolf  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search27.fit(X_train, y_train)\nprint("Greywolf model")\n\nprint("SVC")\n\ngwa_svc= nia_search27.best_estimator_\nmodel47=evaluate(gwa_svc , X_test,  y_test, \'SVC\')\nmodel47.timetaken[0] = time.time() - time1')


# In[119]:


nia_search27.best_params_


# In[120]:


score_by_generation_lineplot(nia_search27)


# In[121]:


print("Classification report of SVC")
print('\n')
clf = SVC(**nia_search27.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[122]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.tree import DecisionTreeClassifier\nparam_grid_dt={\'max_features\': [\'sqrt\'],\n \'max_depth\': [210],\n \'min_samples_split\': [10,20],\n \'min_samples_leaf\': [2,5]}\n\nclf_28 = DecisionTreeClassifier(random_state=42)\n\nnia_search28 = NatureInspiredSearchCV(\n    clf_28,\n    param_grid_dt,\n    cv=3,\n    verbose=2,\n    algorithm=\'gwo\', #   algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search28.fit(X_train, y_train)\nprint("Greywolf  model")\n\nprint("Decision Tree")\n\ngwa_dt= nia_search28.best_estimator_\nmodel48=evaluate(gwa_dt,  X_test,  y_test, \'Decision Tree\')\nmodel48.timetaken[0] = time.time() - time1')


# In[123]:


nia_search28.best_params_


# In[124]:


score_by_generation_lineplot(nia_search28)


# In[125]:


print("Classification report of Decision Tree")
print('\n')
clf = DecisionTreeClassifier(**nia_search28.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# #### PERFORMANCE METRICS GREY WOLF OPTIMIZATION MODEL

# In[126]:


df_gwa= pd.concat([model41,model42,model43,model44,model45,model46,model47,model48],axis = 0).reset_index()
df_gwa.drop('index', axis=1, inplace=True)
df_gwa


# #### FIREFLY ALGORITHM

# In[127]:


get_ipython().run_cell_magic('time', '', '\nfrom sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\ntime1 = time.time()\nparam_grid_rt={\'n_estimators\': [800],\n \'max_features\': [\'sqrt\'],\n \'max_depth\': [60],\n \'min_samples_split\': [2,10,5],\n \'min_samples_leaf\': [1,5,10],\n \'bootstrap\': [True]}\n\nclf_31 = RandomForestClassifier(random_state=42)\nnia_search31 = NatureInspiredSearchCV(\n    clf_31,\n    param_grid_rt,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search31.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("Random Forest")\n\nfa_random= nia_search31.best_estimator_\nmodel51=evaluate(fa_random,  X_test,  y_test, \'Random Forest\')\nmodel51.timetaken[0] = time.time() - time1\n')


# In[128]:


nia_search31.best_params_


# In[129]:


score_by_generation_lineplot(nia_search31)


# In[130]:


print("Classification report of Random Forest")
print('\n')
clf = RandomForestClassifier(**nia_search31.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[131]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.ensemble import ExtraTreesClassifier\nparam_grid_et={\'n_estimators\': [200],\n \'max_features\': [\'auto\'],\n \'max_depth\': [70],\n \'min_samples_split\': [2,10,5],\n \'min_samples_leaf\': [1,2,10],\n \'bootstrap\': [True]}\n\nclf_32 = ExtraTreesClassifier(random_state=42)\n\nnia_search32 = NatureInspiredSearchCV(\n    clf_32,\n    param_grid_et,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search32.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("Extra Tree")\n\nfa_et= nia_search32.best_estimator_\nmodel52=evaluate(fa_et,  X_test,  y_test, \'Extra Tree\')\nmodel52.timetaken[0] = time.time() - time1\n\n')


# In[132]:


nia_search32.best_params_


# In[133]:


score_by_generation_lineplot(nia_search32)


# In[134]:


print("Classification report of Extra Tree")
print('\n')
clf =ExtraTreesClassifier(**nia_search32.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[135]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.linear_model import LogisticRegression\nparam_grid_lr={\'max_iter\': [1200,100], \'solver\': [\'newton-cg\'], \'C\': [4.0,1.0]}\nclf_33 = LogisticRegression(random_state=42)\n\nnia_search33 = NatureInspiredSearchCV(\n    clf_33,\n    param_grid_lr,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search33.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("Logistic Regression")\n\nfa_lr= nia_search33.best_estimator_\nmodel53=evaluate(fa_lr,  X_test,  y_test, \'Logistic Regression\')\nmodel53.timetaken[0] = time.time() - time1')


# In[136]:


nia_search33.best_params_


# In[137]:


score_by_generation_lineplot(nia_search33)


# In[138]:


print("Classification report of Logistic Regression")
print('\n')
clf = LogisticRegression(**nia_search33.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[139]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.neighbors import KNeighborsClassifier\nparam_grid_kn={\'leaf_size\': [133], \'p\': [2,5], \'algorithm\': [\'kd_tree\']}\nclf_34 = KNeighborsClassifier(n_neighbors=42)\n\nnia_search34 = NatureInspiredSearchCV(\n    clf_34,\n    param_grid_kn,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search34.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("KNN")\n\nfa_kn= nia_search34.best_estimator_\nmodel54=evaluate(fa_kn , X_test,  y_test, \'KNN\')\nmodel54.timetaken[0] = time.time() - time1\n')


# In[140]:


nia_search34.best_params_


# In[141]:


score_by_generation_lineplot(nia_search34)


# In[142]:


print("Classification report of KNN")
print('\n')
clf = KNeighborsClassifier(**nia_search34.best_params_, n_neighbors=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[143]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.svm import LinearSVC\nparam_grid_lsvc={\'tol\': [1e-05,0.0001],\'intercept_scaling\': [44,1,55], \'dual\': [False]}\nclf_35 = LinearSVC(random_state=42)\n\nnia_search35 = NatureInspiredSearchCV(\n    clf_35,\n    param_grid_lsvc,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search35.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("LinearSVC")\n\nfa_lsvc= nia_search35.best_estimator_\nmodel55=evaluate(fa_lsvc , X_test,  y_test, \'LinearSVC\')\nmodel55.timetaken[0] = time.time() - time1\n')


# In[144]:


nia_search35.best_params_


# In[145]:


score_by_generation_lineplot(nia_search35)


# In[146]:


print("Classification report of LinearSVC")
print('\n')
clf = LinearSVC(**nia_search35.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[147]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nvar_smoothing=[0.0000000001,0.000001,0.01,0.001,0.00000000000001,1,1e-15,1e-20]\nparam_grid_gnb = {             \n               \'var_smoothing\' : var_smoothing\n               }\nclf_36 = GaussianNB()\n\nnia_search36 = NatureInspiredSearchCV(\n    clf_36,\n    param_grid_gnb,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search36.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("GaussianNB")\n\nfa_gnb= nia_search36.best_estimator_\nmodel56=evaluate(fa_gnb , X_test,  y_test, \'GaussianNB\')\nmodel56.timetaken[0] = time.time() - time1')


# In[148]:


nia_search36.best_estimator_


# In[149]:


score_by_generation_lineplot(nia_search36)


# In[150]:



print("Classification report of GaussianNB")
print('\n')
clf = GaussianNB(**nia_search36.best_params_)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[151]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.svm import SVC\nparam_grid_svc = {\'C\' : [6,10],\n               \'degree\': [4,8],              \n               \'tol\': [0.01,0.1,0.00001],\n               \'cache_size\': [200,1000],\n               \'break_ties\': [False]\n               }\nprint(param_grid_svc)\nclf_37=SVC(random_state=42)\nnia_search37 = NatureInspiredSearchCV(\n    clf_37,\n    param_grid_svc,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly  algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search37.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("SVC")\n\nfa_svc= nia_search37.best_estimator_\nmodel57=evaluate(fa_svc , X_test,  y_test, \'SVC\')\nmodel57.timetaken[0] = time.time() - time1\n')


# In[152]:


nia_search37.best_params_


# In[153]:


score_by_generation_lineplot(nia_search37)


# In[154]:


print("Classification report of SVC")
print('\n')
clf = SVC(**nia_search37.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# In[155]:


get_ipython().run_cell_magic('time', '', 'from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\ntime1 = time.time()\nfrom sklearn.tree import DecisionTreeClassifier\nparam_grid_dt={\'max_features\': [\'auto\'],\n \'max_depth\': [110],\n \'min_samples_split\': [5,2,10],\n \'min_samples_leaf\': [1,5,10]}\n\nclf_38 = DecisionTreeClassifier(random_state=42)\n\nnia_search38 = NatureInspiredSearchCV(\n    clf_38,\n    param_grid_dt,\n    cv=3,\n    verbose=2,\n    algorithm=\'fa\', #  Firefly algorithm\n    population_size=50,\n    max_n_gen=100,\n    max_stagnating_gen=20,\n    runs=5,\n    n_jobs=-1,\n    random_state=42,\n    \n    # or any number if you want same results on each run\n)\n\n\nnia_search38.fit(X_train, y_train)\nprint("Firefly model")\n\nprint("Decision Tree")\n\nfa_dt= nia_search38.best_estimator_\nmodel58=evaluate(fa_dt,  X_test,  y_test, \'Decision Tree\')\nmodel58.timetaken[0] = time.time() - time1')


# In[156]:


nia_search38.best_params_


# In[157]:


score_by_generation_lineplot(nia_search38)


# In[158]:


print("Classification report of Decision Tree")
print('\n')
clf = DecisionTreeClassifier(**nia_search38.best_params_, random_state=42)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred, digits=4))


# #### PERFORMANCE METRICS OF FIREFLY MODEL

# In[159]:


df_fa= pd.concat([model51,model52,model53,model54,model55,model56,model7,model58],axis = 0).reset_index()
df_fa.drop('index', axis=1, inplace=True)
df_fa


# In[160]:


df_base


# In[161]:


df_randomized


# In[162]:


df_bat


# In[163]:


df_hba


# In[164]:


df_gwa


# In[165]:


df_fa


# ### COMPARISION AMONG THE TECHNIQUES

# #### BASE MODEL VS OTHER TECHNIQUES

# In[166]:


print("COMPARISION OF BASE LINE MODEL AND RANDOMIZED MODEL")

comp_base_randomized = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_base_randomized.model = df_base.model
for i in range(1,8):
    for j in range(8):
        if df_base[df_base.columns[i]][j] < df_randomized[df_randomized.columns[i]][j]:
            comp_base_randomized[comp_base_randomized.columns[i]][j] = 1
comp_base_randomized


# In[167]:


print("COMPARISION OF BASE LINE MODEL AND BAT ALGORITHM")

comp_base_ba = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_base_ba.model = df_base.model
for i in range(1,8):
    for j in range(8):
        if df_base[df_base.columns[i]][j] < df_bat[df_bat.columns[i]][j]:
            comp_base_ba[comp_base_ba.columns[i]][j] = 1
comp_base_ba


# In[168]:


print("COMPARISION OF BASE LINE MODEL AND HYBRID BAT ALGORITHM")

comp_base_hba = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_base_hba.model = df_base.model
for i in range(1,8):
    for j in range(8):
        if df_base[df_base.columns[i]][j] < df_hba[df_hba.columns[i]][j]:
            comp_base_hba[comp_base_hba.columns[i]][j] = 1
comp_base_hba


# In[169]:


print("COMPARISION OF BASE LINE MODEL AND GREY WOLF ALGORITHM")

comp_base_gwa = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_base_gwa.model = df_base.model
for i in range(1,8):
    for j in range(8):
        if df_base[df_base.columns[i]][j] < df_gwa[df_gwa.columns[i]][j]:
            comp_base_gwa[comp_base_gwa.columns[i]][j] = 1
comp_base_gwa


# In[170]:


print("COMPARISION OF BASE LINE MODEL AND FIREFLY ALGORITHM")

comp_base_fa = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_base_fa.model = df_base.model
for i in range(1,8):
    for j in range(8):
        if df_base[df_base.columns[i]][j] < df_fa[df_fa.columns[i]][j]:
            comp_base_fa[comp_base_fa.columns[i]][j] = 1
comp_base_fa


# #### RANDOMIZED SEARCH VS NATURE INSPIRIED ALGORITHM

# In[171]:


print("COMPARISION OF RANDOMIZED MODEL AND BAT ALOGORITHM")

comp_bat_randomized = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_bat_randomized.model = df_randomized.model
for i in range(1,8):
    for j in range(8):
        if df_bat[df_bat.columns[i]][j] > df_randomized[df_randomized.columns[i]][j]:
            comp_bat_randomized[comp_bat_randomized.columns[i]][j] = 1
comp_bat_randomized


# In[172]:


print("COMPARISION OF RANDOMIZED MODEL AND HYBRID BAT ALOGORITHM")

comp_hba_randomized = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_hba_randomized.model = df_randomized.model
for i in range(1,8):
    for j in range(8):
        if df_hba[df_hba.columns[i]][j] > df_randomized[df_randomized.columns[i]][j]:
            comp_hba_randomized[comp_hba_randomized.columns[i]][j] = 1
comp_hba_randomized


# In[173]:


print("COMPARISION OF RANDOMIZED MODEL AND GREYWOLF ALOGORITHM")

comp_gwa_randomized = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_gwa_randomized.model = df_randomized.model
for i in range(1,8):
    for j in range(8):
        if df_gwa[df_gwa.columns[i]][j] > df_randomized[df_randomized.columns[i]][j]:
            comp_gwa_randomized[comp_gwa_randomized.columns[i]][j] = 1
comp_gwa_randomized


# In[174]:


print("COMPARISION OF RANDOMIZED MODEL AND FIREFLY ALOGORITHM")

comp_fa_randomized = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_fa_randomized.model = df_randomized.model
for i in range(1,8):
    for j in range(8):
        if df_fa[df_fa.columns[i]][j] > df_randomized[df_randomized.columns[i]][j]:
            comp_fa_randomized[comp_fa_randomized.columns[i]][j] = 1
comp_fa_randomized


# #### COMPARISION AMONG NATURE INSPIRIED ALGORITHMS

# ##### HBA VS OTHER NIA'S

# In[175]:


print("COMPARISION OF HYBRID BAT AND BAT ALOGORITHM")

comp_bat_hba = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_bat_hba.model = df_bat.model
for i in range(1,8):
    for j in range(8):
        if df_bat[df_bat.columns[i]][j] > df_hba[df_hba.columns[i]][j]:
            comp_bat_hba[comp_bat_hba.columns[i]][j] = 1
comp_bat_hba


# In[176]:


print("COMPARISION OF HYBRID BAT AND GREYWOLF ALOGORITHM")

comp_gwa_hba = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_gwa_hba.model = df_gwa.model
for i in range(1,8):
    for j in range(8):
        if df_gwa[df_gwa.columns[i]][j] > df_hba[df_hba.columns[i]][j]:
            comp_gwa_hba[comp_gwa_hba.columns[i]][j] = 1
comp_gwa_hba


# In[177]:


print("COMPARISION OF HYBRID BAT AND FIREFLY ALOGORITHM")

comp_fa_hba = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_fa_hba.model = df_fa.model
for i in range(1,8):
    for j in range(8):
        if df_fa[df_fa.columns[i]][j] > df_hba[df_hba.columns[i]][j]:
            comp_fa_hba[comp_fa_hba.columns[i]][j] = 1
comp_fa_hba


# ##### BA VS OTHER NIA'S

# In[178]:


print("COMPARISION OF BAT AND FIREFLY ALOGORITHM")

comp_fa_bat = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_fa_bat.model = df_fa.model
for i in range(1,8):
    for j in range(8):
        if df_fa[df_fa.columns[i]][j] > df_bat[df_bat.columns[i]][j]:
            comp_fa_bat[comp_fa_bat.columns[i]][j] = 1
comp_fa_bat


# In[179]:


print("COMPARISION OF BAT AND GREYWOLF ALOGORITHM")

comp_gwa_bat = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_gwa_bat.model = df_gwa.model
for i in range(1,8):
    for j in range(8):
        if df_gwa[df_gwa.columns[i]][j] > df_bat[df_bat.columns[i]][j]:
            comp_gwa_bat[comp_gwa_bat.columns[i]][j] = 1
comp_gwa_bat


# ##### GWA VS FA

# In[180]:


print("COMPARISION OF FIREFLY AND GREYWOLF ALOGORITHM")

comp_gwa_fa = pd.DataFrame({'model': [0]*8,'accuracy': [0]*8,'precision': [0]*8,'recall': [0]*8,'f1score': [0]*8,'rocauc': [0]*8,'logloss': [0]*8,'timetaken': [0]*8})
comp_gwa_fa.model = df_gwa.model
for i in range(1,8):
    for j in range(8):
        if df_gwa[df_gwa.columns[i]][j] > df_fa[df_fa.columns[i]][j]:
            comp_gwa_fa[comp_gwa_fa.columns[i]][j] = 1
comp_gwa_fa


# ### PLOT REPRESENTATION OF PERFORMANCE METRICS

# #### BASE LINE MODEL

# In[181]:


print("Base Model")
print('\n')

fig, ax = plt.subplots(7, 1, figsize=(20, 30))

ax[0].bar(df_base.model,df_base.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_base.model, df_base.precision)
ax[1].set_title('precision')

ax[2].bar(df_base.model, df_base.recall)
ax[2].set_title('recall')

ax[3].bar(df_base.model, df_base.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_base.model, df_base.rocauc)
ax[4].set_title('AUC-score')                                                                                          
                                                                                                                   
ax[5].bar(df_base.model, df_base.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_base.model, df_base.timetaken)
ax[6].set_title('Time taken')

# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# #### RANDOMIZED MODEL

# In[182]:


print("Randomized Model")
print('\n')
fig, ax = plt.subplots(7, 1, figsize=(20, 35))
plt.ylim(0.001,15)
ax[0].bar(df_randomized.model, df_randomized.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_randomized.model, df_randomized.precision)
ax[1].set_title('precision')

ax[2].bar(df_randomized.model, df_randomized.recall)
ax[2].set_title('recall')


ax[3].bar(df_randomized.model, df_randomized.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_randomized.model,df_randomized.rocauc)
ax[4].set_title('AUC-score')

ax[5].bar(df_randomized.model, df_randomized.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_randomized.model, df_randomized.timetaken)
ax[6].set_title('Time taken')


# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# #### BAT MODEL

# In[183]:


print("Bat Model")
print('\n')
fig, ax = plt.subplots(7, 1, figsize=(15, 30))
ax[0].bar(df_bat.model, df_bat.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_bat.model, df_bat.precision)
ax[1].set_title('precision')

ax[2].bar(df_bat.model, df_bat.recall)
ax[2].set_title('recall')

ax[3].bar(df_bat.model, df_bat.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_bat.model, df_bat.rocauc)
ax[4].set_title('AUC-score')                                                                                          
                                                                                                                   
ax[5].bar(df_bat.model, df_bat.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_bat.model, df_bat.timetaken)
ax[6].set_title('Time taken')

# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# #### HYBRID BAT MODEL

# In[184]:


print("Hybrid Bat Model")
print('\n')
fig, ax = plt.subplots(7, 1, figsize=(15, 30))

ax[0].bar(df_hba.model, df_hba.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_hba.model, df_hba.precision)
ax[1].set_title('precision')

ax[2].bar(df_hba.model, df_hba.recall)
ax[2].set_title('recall')

ax[3].bar(df_hba.model, df_hba.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_hba.model, df_hba.rocauc)
ax[4].set_title('AUC-score')                                                                                          
                                                                                                                   
ax[5].bar(df_hba.model, df_hba.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_hba.model, df_hba.timetaken)
ax[6].set_title('Time taken')

# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# #### GERY WOLF MODEL

# In[185]:


print("Grey Wolf Model")
print('\n')
fig, ax = plt.subplots(7, 1, figsize=(15, 30))

ax[0].bar(df_gwa.model, df_gwa.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_gwa.model, df_gwa.precision)
ax[1].set_title('precision')

ax[2].bar(df_gwa.model, df_gwa.recall)
ax[2].set_title('recall')

ax[3].bar(df_gwa.model, df_gwa.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_gwa.model, df_gwa.rocauc)
ax[4].set_title('AUC-score')                                                                                          
                                                                                                                   
ax[5].bar(df_gwa.model, df_gwa.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_gwa.model, df_gwa.timetaken)
ax[6].set_title('Time taken')

# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# #### FIREFLY MODEL

# In[186]:


print("Firefly Model")
print('\n')
fig, ax = plt.subplots(7, 1, figsize=(15, 30))

ax[0].bar(df_fa.model, df_fa.accuracy)
ax[0].set_title('accuracy')

ax[1].bar(df_fa.model, df_fa.precision)
ax[1].set_title('precision')

ax[2].bar(df_fa.model, df_fa.recall)
ax[2].set_title('recall')

ax[3].bar(df_fa.model, df_fa.f1score)
ax[3].set_title('F1-score')

ax[4].bar(df_fa.model, df_fa.rocauc)
ax[4].set_title('AUC-score')                                                                                          
                                                                                                                   
ax[5].bar(df_fa.model, df_fa.logloss)
ax[5].set_title('Log-Loss-Score')

ax[6].bar(df_fa.model, df_fa.timetaken)
ax[6].set_title('Time taken')

# Fine-tune figure; make subplots farther from each other, or nearer to each other.
fig.subplots_adjust(hspace=0.5, wspace=0.5)


# In[187]:


import pickle
file = open('random_forest_nia_model.pkl','wb')
pickle.dump(ba_random,file)


# In[ ]:




